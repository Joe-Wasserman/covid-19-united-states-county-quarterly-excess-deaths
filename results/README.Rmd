---
title: "COVID-19 United States Excess Deaths by county and quarter: Model comparison and selection"
output: github_document
---

<!-- /results/README.md is generated from /results/README.Rmd. Please edit that file -->

```{r setup, include=FALSE}
library(tidyverse)
library(furrr)
library(tidycensus)
library(data.table)
library(lubridate)
library(aweek)
library(lme4)
library(knitr)
# library(kableExtra)

knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  collapse = TRUE,
  include = FALSE,
  dev.args = list(png = list(type = "cairo")), dpi = 96,
  fig.path = "README_files/"
)

options(
  scipen = 999,
  digits = 3,
  future.globals.maxSize = 1000000*1024,
  knitr.kable.NA = "n/a"
)

set.seed(20201007)

source(
  file.path(here::here(), "code/estimate_excess_deaths.R")
)

```

```{r read chunk, include=FALSE, cache=FALSE}
knitr::read_chunk(
  file.path(
    here::here(),
    "code/clean_data_and_model.R"
  )
)
```

```{r import, message=TRUE, warning=TRUE}
```

```{r conform-data, message=TRUE, warning=TRUE}
```

# Model comparison strategy

Several models with alternate specifications of random grouping factors were evaluated.
To select a model, they were compared in terms of:

1. Performance on 2015-2019 training data

2. Performance on Q1 2020 data

3. Outlier estimates in training data

# Intraclass correlations

First, we examined the intraclass correlation coefficients for each specification to evaluate their reasonableness.

```{r icc, include=FALSE, message=FALSE, warning=FALSE}
```

```{r icc output, include=TRUE, results='asis'}
icc %>% 
  walk(
    ~ .x %>%
  kable(format = "pipe") %>% 
    print()
  )
```

# Model specifications

```{r models, include=TRUE, echo=TRUE}
```

# Performance on 2015-2019 training data

```{r training-performance}
```

Compare model performance indices for all five models.
Although many models perform similarly for these metrics, when taken together and with a focus on AIC and BIC, model 8 (counties nested within county sets nested within states) and model 12 (counties nested within county sets nested within states nested within census regions) appear to be the top two contenders.

```{r training performance output, include=TRUE, results='asis'}
model_performance %>%
  kable(
    format = "pipe",
    caption = "Model Performance"
  )
```

# Performance on Q1 2020 data

Compare mean squared error (MSE) of model-predicted death rates against observed death rates in Q1 2020.
Because the COVID-19 pandemic only began partway through March, 2020, we can evaluate model performance by examining concordance of predicted and observed deaths in Q1 2020.
Models 5, 8, 11, and 12 have the lowest MSE.

```{r validation-performance}
```

```{r validation performance output, include=TRUE, results='asis'}
model_mse %>%
  kable(
    format = "pipe",
    caption = "Mean Squared Error of Alternate Models"
  )
```

# Outlier estimates

To evaluate the extent of outlier model predictions, including unexpectedly large changes quarter-to-quarter, time series outliers were identified using `tsoutliers()` from the {[forecast](https://cran.r-project.org/package=forecast)} R package.
Using this method, only models 2 and 3 had no outliers.
Potential outliers identified for other states were concentrated in several Mountain West counties with zero non-censored values 2015-2019, and therefore mostly predicted values of zero.
In the following plots for each model and county with outliers, grey lines are predicted values and blue dots represent values that `tsoutliers()` suggests as replacements for outliers.

```{r volatility}
```

```{r volatility summary output, include=TRUE, results='asis'}
model_volatility_summary %>%
  kable(
    format = "pipe",
    caption = "Summary of Model Outliers"
  )
```


```{r plot-volatility}
```

```{r plot volatility output, include=TRUE, error=FALSE}
print(fitted_outlier_plots)
```

# Final model

Based on these results, model 8 was selected as the final model.
In this model, **total deaths per day** was regressed on:
  
  * county population (z-scored)
  
  * years since 2015
  
  * quarter of the year (fixed grouping factor)
  
  * county (random grouping factor nested within county set)
  
  * county set (random grouping factor nested within state)
  
  * state (random grouping factor)

```{r final-model}
```

## Model coefficients (fixed and random effects)

```{r final-model output, include=TRUE, results='asis'}
united_states_county_quarterly_results[[1]] %>% 
  broom.mixed::tidy() %>% 
    kable(
    format = "pipe"
  )
```


```{r, include=TRUE, echo=TRUE}
sessionInfo()
```
